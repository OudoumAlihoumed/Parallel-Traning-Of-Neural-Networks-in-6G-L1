# Parallel-Traning-Of-Neural-Networks-in-6G-L1

This thesis revolves around the parallel training of neural networks, with a keen eye on the applicability within 6G L1. Recognizing the critical role that neural networks will play in the evolving landscape of 6G, the research aims to train neural networks with better resource utilization.
The thesis opens with a comprehensive overview of neural networks and their pivotal role in 6G L1. Parallel training methods, specifically data parallel using DistributedDataParallel (DDP), are introduced as key strategies for enhancing the efficiency of the training process.
A set of extensive experiments using CIFAR-10 and ImageNet datasets is conducted, with ResNet models utilized as stand-ins for 6G L1 models. This enables the focus to remain on optimizing parallel training strategies rather than model specifics. The experimental setup involves non-distributed GPU servers and Kubernetes environments with Multi-Instance GPU (MIG) and leverages PyTorch's DDP for distributed training. Significant attention is given to optimizing GPU throughput, disk bandwidth, and data loading for enhanced resource utilization.
The results obtained offer significant insights, with the key finding being that DDP leads to remarkable improvements in the training process of neural networks. Further, the thesis includes in-depth analysis and discussion on topics like the influence of global batch size on model performance and the utilization of MIGs.
